# Hi, I'm Joseph Luker 👋

Data Engineer, but in my free time I'm ~obsessing~ passionately exploring AI interpretability.

## 🔬 Research Interests
- Mechanistic interpretability of neural networks
- Understanding how language models represent and process information
- Building tools for AI safety and alignment research

## 🛠️ Featured Projects
- **[TEMPO]([link](https://github.com/JoeLuker/tempo))**: Novel approach to LLM inference exploring parallel token processing for interpretability
- **[Vardon]([link](https://github.com/JoeLuker/Vardon))**: Pathfinder 1e character engine (Work in Progress)
- **[AONPRD-Parse]([link](https://github.com/JoeLuker/Vardon))**: High-performance async data pipeline demonstrating engineering expertise

## 💡 Philosophy
I believe understanding *how* AI systems work internally is crucial for building safe, aligned AI. My work bridges practical engineering with theoretical understanding of machine learning principles.
