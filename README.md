# Hi, I'm Joseph Luker 👋

Data Engineer passionate about AI interpretability and building reliable, understandable AI systems.

## 🔬 Research Interests
- Mechanistic interpretability of neural networks
- Understanding how language models represent and process information
- Building tools for AI safety and alignment research

## 🛠️ Featured Projects
- **[TEMPO](link)**: Novel approach to LLM inference exploring parallel token processing for interpretability
- **[MI Experiments](link)**: Mechanistic interpretability research using representation engineering
- **[AONPRD-Parse](link)**: High-performance async data pipeline demonstrating engineering expertise

## 💡 Philosophy
I believe understanding *how* AI systems work internally is crucial for building safe, aligned AI. My work bridges practical engineering with theoretical understanding of neural computation.
