# Hi, I'm Joseph Luker ğŸ‘‹

Data Engineer passionate about AI interpretability and building reliable, understandable AI systems.

## ğŸ”¬ Research Interests
- Mechanistic interpretability of neural networks
- Understanding how language models represent and process information
- Building tools for AI safety and alignment research

## ğŸ› ï¸ Featured Projects
- **[TEMPO](link)**: Novel approach to LLM inference exploring parallel token processing for interpretability
- **[MI Experiments](link)**: Mechanistic interpretability research using representation engineering
- **[AONPRD-Parse](link)**: High-performance async data pipeline demonstrating engineering expertise

## ğŸ’¡ Philosophy
I believe understanding *how* AI systems work internally is crucial for building safe, aligned AI. My work bridges practical engineering with theoretical understanding of neural computation.
